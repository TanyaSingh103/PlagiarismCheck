{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "What the test data looks like:\n",
        "\n",
        "test1.cpp - original submission from a student\n",
        "\n",
        "test2.cpp - exact copy of test1\n",
        "\n",
        "test3.cpp - original submission from a student\n",
        "\n",
        "test4.cpp - original submission from a student\n",
        "\n",
        "test5.cpp - original submission from a student\n",
        "\n",
        "test6.cpp - changed muliple variable and function names from test1\n"
      ],
      "metadata": {
        "id": "nN76oGyfw0aX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wQaIza29-mRE"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "def remove_comments_and_headers(code):\n",
        "    code = re.sub(r'//.*', '', code)\n",
        "    code = re.sub(r'/\\*[\\s\\S]*?\\*/', '', code)\n",
        "    code = re.sub(r'#include\\s*<.*>', '', code)\n",
        "    code = re.sub(r'#include\\s*\".*\"', '', code)\n",
        "    code = re.sub(r'using\\s+namespace\\s+std;', '', code)\n",
        "    code = re.sub(r';', '', code)\n",
        "    return code\n",
        "\n",
        "def normalize_whitespace(code):\n",
        "    code = code.strip()\n",
        "    code = re.sub(r'\\s+', ' ', code)\n",
        "    code = re.sub(r'\\n+', '\\n', code)\n",
        "    return code\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_code(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        code = file.read()\n",
        "    code = remove_comments_and_headers(code)\n",
        "    code = normalize_whitespace(code)\n",
        "    return code"
      ],
      "metadata": {
        "id": "54ev5mF6_Nbl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_files(directory):\n",
        "    preprocessed_files = {}\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        preprocessed_files[filename] = preprocess_code(file_path)\n",
        "    return preprocessed_files"
      ],
      "metadata": {
        "id": "1zWL4MSe_LSb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/data/tests'\n",
        "preprocessed_files = preprocess_files(directory)"
      ],
      "metadata": {
        "id": "QKczV-I9_Ibl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename, preprocessed_code in preprocessed_files.items():\n",
        "    print(f\"--- Preprocessed code for {filename} ---\")\n",
        "    print(preprocessed_code)\n",
        "    print(\"------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heudSE7L_Dhv",
        "outputId": "7dd43b44-e7d5-4093-f74d-395bb88eafa9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Preprocessed code for test4.cpp ---\n",
            "int solve(vector<int> ar, int n, int i, vector<int> dp) { if(i == n) return 1 if(dp[i] != -1) return dp[i] int include = 0, exclude = 0 if(ar[i] > ar[i-1]) include = 1 + solve(ar, n, i+1, dp) exclude = 0 + solve(ar, n, i+1, dp) return dp[i] = max(include, exclude) } int main() { vector<int> ar1 = {10,20,30,35,40,45} int n1 = ar1.size() vector<int> dp1(n1, -1) cout << \"Test case 1 : \" << solve(ar1, n1, 1, dp1) vector<int> ar2 = {5,4,3,2,1} int n2 = ar2.size() vector<int> dp2(n2, -1) cout << \"\\nTest case 2 : \" << solve(ar2, n2, 1, dp2) return 0 }\n",
            "------------------------------------------\n",
            "--- Preprocessed code for test6.cpp ---\n",
            "int longestInc(vector<int>& arr,int curr,int prev,vector<vector<int>>dp) { if(curr==arr.size()) return 0 if(dp[curr][prev+1]!=-1) return dp[curr][prev+1] int exclude = 0 + longest_inc(arr, curr+1, prev, dp) int include=0 if(prev==-1||arr[curr]>arr[prev]){ include=1+longest_inc(arr,curr+1,curr,dp) } dp[curr][prev+1] = max(include, exclude) return dp[curr][prev+1] } int main() { vector<int>arr1={10,20,30,25,35,40,45} vector<int>arr2={5, 4, 3, 2, 1} int n=arr1.size() int prev=-1,curr=0 vector<vector<int>> dp(n, vector<int>(n, -1)) cout<<\"LIS for test case 1:\"<<longest_inc(arr1,curr,prev,dp)<<endl cout<<\"LIS for test case 2:\"<<longest_inc(arr2,curr,prev,dp) }\n",
            "------------------------------------------\n",
            "--- Preprocessed code for test5.cpp ---\n",
            "int stockPrice(vector<int>& arr, int n, int curr, int prev, vector<vector<int>>& dp) { if (curr == n) return 0 if (dp[curr][prev + 1] != -1) return dp[curr][prev + 1] int include = 0, exclude = 0 if (prev == -1 || arr[curr] >= arr[prev]) include = arr[curr] + stockPrice(arr, n, curr + 1, curr, dp) exclude = stockPrice(arr, n, curr + 1, prev, dp) dp[curr][prev + 1] = max(include, exclude) return dp[curr][prev + 1] } int maxProfit(vector<int>& stocks) { int n = stocks.size() vector<vector<int>> dp(n, vector<int>(n + 1, -1)) return stockPrice(stocks, n, 0, -1, dp) } int main() { vector<int> stocks = {10, 20, 30, 25, 35, 40, 45} cout << \"Maximum profit: \" << maxProfit(stocks) << endl return 0 }\n",
            "------------------------------------------\n",
            "--- Preprocessed code for test3.cpp ---\n",
            "int solve(int curr,int prev,vector<int> &nums,vector<vector<int>> &dp) { if(curr >= nums.size() ) { return 0 } if(dp[curr][prev+1] != -1) { return dp[curr][prev+1] } int take = INT_MIN if(prev == -1 || nums[curr] > nums[prev]) { take = 1 + solve(curr + 1,curr,nums,dp) } int not_take = solve(curr+1,prev,nums,dp) return dp[curr][prev+1] = max(take,not_take) } void increasing_streak(vector<int> v) { vector<vector<int>> dp(v.size(),vector<int>(v.size(),-1)) int ans = solve(0,-1,v,dp) if(ans == 0) { cout<<\"Null array has been passed\"<<endl } else if(ans == 1) { cout<<\"There are no increasing streaks the longest streak with rising prices is of length 1.\"<<endl } else { cout<<ans<<endl } } int main() { vector<int> v1 = {10,20,30,25,35,40,45} increasing_streak(v1) vector<int> v2 = {5,4,3,2,1} increasing_streak(v2) vector<int> v3 = {} increasing_streak(v3) vector<int> v4 = {1} increasing_streak(v4) vector<int> v5 = {2,8,9,11,1,9,-1,4,6} increasing_streak(v5) vector<int> v6 = {5,10,4,6,7,8} increasing_streak(v6) }\n",
            "------------------------------------------\n",
            "--- Preprocessed code for test1.cpp ---\n",
            "int longest_inc(vector<int>& arr,int curr,int prev,vector<vector<int>>dp) { if(curr==arr.size()) return 0 if(dp[curr][prev+1]!=-1) return dp[curr][prev+1] int notTake = 0 + longest_inc(arr, curr+1, prev, dp) int take=0 if(prev==-1||arr[curr]>arr[prev]){ take=1+longest_inc(arr,curr+1,curr,dp) } return dp[curr][prev+1] = max(take, notTake) } int main() { vector<int>arr={10,20,30,25,35,40,45} vector<int>arr1={5, 4, 3, 2, 1} int n=arr.size() int prev=-1,curr=0 vector<vector<int>> dp(n, vector<int>(n, -1)) cout<<\"Longest increasing subsequence for test case 1 is:\"<<longest_inc(arr,curr,prev,dp)<<endl cout<<\"Longest increasing subsequence for test case 2 is:\"<<longest_inc(arr1,curr,prev,dp) }\n",
            "------------------------------------------\n",
            "--- Preprocessed code for test2.cpp ---\n",
            "int longest_inc(vector<int>& arr,int curr,int prev,vector<vector<int>>dp) { if(curr==arr.size()) return 0 if(dp[curr][prev+1]!=-1) return dp[curr][prev+1] int notTake = 0 + longest_inc(arr, curr+1, prev, dp) int take=0 if(prev==-1||arr[curr]>arr[prev]){ take=1+longest_inc(arr,curr+1,curr,dp) } return dp[curr][prev+1] = max(take, notTake) } int main() { vector<int>arr={10,20,30,25,35,40,45} vector<int>arr1={5, 4, 3, 2, 1} int n=arr.size() int prev=-1,curr=0 vector<vector<int>> dp(n, vector<int>(n, -1)) cout<<\"Longest increasing subsequence for test case 1 is:\"<<longest_inc(arr,curr,prev,dp)<<endl cout<<\"Longest increasing subsequence for test case 2 is:\"<<longest_inc(arr1,curr,prev,dp) }\n",
            "------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "QbeXkc_U_nkc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = [token.split() for code in preprocessed_files.values() for token in code.split()]\n",
        "\n",
        "word2vec_model = Word2Vec(sentences=all_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "word2vec_model.save(\"word2vec_model.bin\")"
      ],
      "metadata": {
        "id": "_oWclYiI_-A8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "LDckfbpz__RY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embeddings(model, code):\n",
        "    embeddings = []\n",
        "    for token in code.split():\n",
        "        if token in model.wv:\n",
        "            embeddings.append(model.wv[token])\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "ksUzVXjrAhBR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_similarity(embeddings1, embeddings2):\n",
        "    if not embeddings1 or not embeddings2:\n",
        "        return 0.0\n",
        "    similarity_matrix = cosine_similarity(embeddings1, embeddings2) * 10\n",
        "    return similarity_matrix.mean()"
      ],
      "metadata": {
        "id": "OQ74rP-UAnNH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename1, code1 in preprocessed_files.items():\n",
        "    for filename2, code2 in preprocessed_files.items():\n",
        "        if filename1 < filename2:\n",
        "            embeddings1 = generate_embeddings(word2vec_model, code1)\n",
        "            embeddings2 = generate_embeddings(word2vec_model, code2)\n",
        "            similarity = calculate_similarity(embeddings1, embeddings2)\n",
        "            print(f\"Similarity between {filename1} and {filename2}: {similarity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR5cVD0nAlgY",
        "outputId": "e3c7e703-bf53-4cb5-d94a-4b7dc28bc4d3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between test4.cpp and test6.cpp: 0.17415085434913635\n",
            "Similarity between test4.cpp and test5.cpp: 0.22890661656856537\n",
            "Similarity between test5.cpp and test6.cpp: 0.17923347651958466\n",
            "Similarity between test3.cpp and test4.cpp: 0.19106075167655945\n",
            "Similarity between test3.cpp and test6.cpp: 0.13860298693180084\n",
            "Similarity between test3.cpp and test5.cpp: 0.18163923919200897\n",
            "Similarity between test1.cpp and test4.cpp: 0.1795368492603302\n",
            "Similarity between test1.cpp and test6.cpp: 0.2615128755569458\n",
            "Similarity between test1.cpp and test5.cpp: 0.1804451197385788\n",
            "Similarity between test1.cpp and test3.cpp: 0.14582641422748566\n",
            "Similarity between test1.cpp and test2.cpp: 0.2974817156791687\n",
            "Similarity between test2.cpp and test4.cpp: 0.1795368492603302\n",
            "Similarity between test2.cpp and test6.cpp: 0.2615128755569458\n",
            "Similarity between test2.cpp and test5.cpp: 0.1804451197385788\n",
            "Similarity between test2.cpp and test3.cpp: 0.14582641422748566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.25"
      ],
      "metadata": {
        "id": "Vm6iDVRMArcr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_plagiarized_code(preprocessed_files, word2vec_model, threshold):\n",
        "    plagiarized_pairs = []\n",
        "    for filename1, code1 in preprocessed_files.items():\n",
        "        for filename2, code2 in preprocessed_files.items():\n",
        "            if filename1 < filename2:\n",
        "                embeddings1 = generate_embeddings(word2vec_model, code1)\n",
        "                embeddings2 = generate_embeddings(word2vec_model, code2)\n",
        "                similarity = calculate_similarity(embeddings1, embeddings2)\n",
        "                if similarity > threshold:\n",
        "                    plagiarized_pairs.append((filename1, filename2, similarity))\n",
        "    return plagiarized_pairs\n"
      ],
      "metadata": {
        "id": "k9A15GWuA-eC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plagiarized_pairs = identify_plagiarized_code(preprocessed_files, word2vec_model, threshold)"
      ],
      "metadata": {
        "id": "amgOxklKA7Nt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pair in plagiarized_pairs:\n",
        "    filename1, filename2, similarity = pair\n",
        "    print(f\"Plagiarized code pair: {filename1} and {filename2}, Similarity: {similarity}\")\n"
      ],
      "metadata": {
        "id": "QrKlu1paA5sS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745df728-b573-4ada-98d6-c7b9e0feeaee"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plagiarized code pair: test1.cpp and test6.cpp, Similarity: 0.2615128755569458\n",
            "Plagiarized code pair: test1.cpp and test2.cpp, Similarity: 0.2974817156791687\n",
            "Plagiarized code pair: test2.cpp and test6.cpp, Similarity: 0.2615128755569458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "def remove_comments_and_headers(code):\n",
        "    code = re.sub(r'//.*', '', code)  # Single-line comments\n",
        "    code = re.sub(r'/\\*[\\s\\S]*?\\*/', '', code)  # Multi-line comments\n",
        "    code = re.sub(r'#include\\s*<.*>', '', code)  # Remove system headers\n",
        "    code = re.sub(r'#include\\s*\".*\"', '', code)  # Remove local headers\n",
        "    code = re.sub(r'using\\s+namespace\\s+std\\s*;', '', code)  # Remove using namespace std\n",
        "    return code\n",
        "\n",
        "def normalize_whitespace(code):\n",
        "    code = re.sub(r'\\s+', ' ', code)  # Normalize all whitespace to a single space\n",
        "    code = re.sub(r'\\n+', '\\n', code)  # Normalize multiple newlines to a single newline\n",
        "    return code.strip()\n",
        "\n",
        "def preprocess_code(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            code = file.read()\n",
        "        code = remove_comments_and_headers(code)\n",
        "        code = normalize_whitespace(code)\n",
        "        return code\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_path}: {e}\")\n",
        "        return \"\"\n"
      ],
      "metadata": {
        "id": "pltPDPTZmERm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_files(directory):\n",
        "    preprocessed_files = {}\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".cpp\") or filename.endswith(\".h\"):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            preprocessed_files[filename] = preprocess_code(file_path)\n",
        "    return preprocessed_files\n"
      ],
      "metadata": {
        "id": "YTOrN3fMmRxH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def generate_embeddings(model, code):\n",
        "    embeddings = [model.wv[token] for token in code.split() if token in model.wv]\n",
        "    return np.array(embeddings)\n",
        "\n",
        "def calculate_similarity(embeddings1, embeddings2):\n",
        "    if embeddings1.size == 0 or embeddings2.size == 0:\n",
        "        return 0.0\n",
        "    similarity_matrix = cosine_similarity(embeddings1, embeddings2)\n",
        "    return similarity_matrix.mean()\n"
      ],
      "metadata": {
        "id": "IVJP1ryEmUpB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_plagiarized_code(preprocessed_files, word2vec_model, threshold):\n",
        "    plagiarized_pairs = []\n",
        "    files = list(preprocessed_files.items())\n",
        "    for i in range(len(files)):\n",
        "        filename1, code1 = files[i]\n",
        "        embeddings1 = generate_embeddings(word2vec_model, code1)\n",
        "        for j in range(i + 1, len(files)):\n",
        "            filename2, code2 = files[j]\n",
        "            embeddings2 = generate_embeddings(word2vec_model, code2)\n",
        "            similarity = calculate_similarity(embeddings1, embeddings2)\n",
        "            if similarity > threshold:\n",
        "                plagiarized_pairs.append((filename1, filename2, similarity))\n",
        "    return plagiarized_pairs\n"
      ],
      "metadata": {
        "id": "7sgoNttEmWWR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/data/tests'\n",
        "threshold = 0\n",
        "model_path = \"word2vec_model.bin\"\n",
        "preprocessed_files = preprocess_files(directory)\n",
        "\n",
        "all_tokens = [token.split() for code in preprocessed_files.values() for token in code.split()]\n",
        "word2vec_model = Word2Vec(sentences=all_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "word2vec_model.save(model_path)\n",
        "\n",
        "plagiarized_pairs = identify_plagiarized_code(preprocessed_files, word2vec_model, threshold)\n",
        "for filename1, filename2, similarity in plagiarized_pairs:\n",
        "    print(f\"Plagiarized code pair: {filename1} and {filename2}, Similarity: {similarity}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wd-kE10mhv0",
        "outputId": "70fb5003-550d-43c8-ca8b-e7ec3e8cf7bc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plagiarized code pair: test4.cpp and test6.cpp, Similarity: 0.018834834918379784\n",
            "Plagiarized code pair: test4.cpp and test5.cpp, Similarity: 0.022038480266928673\n",
            "Plagiarized code pair: test4.cpp and test3.cpp, Similarity: 0.018189571797847748\n",
            "Plagiarized code pair: test4.cpp and test1.cpp, Similarity: 0.014911038801074028\n",
            "Plagiarized code pair: test4.cpp and test2.cpp, Similarity: 0.014911038801074028\n",
            "Plagiarized code pair: test6.cpp and test5.cpp, Similarity: 0.017952190712094307\n",
            "Plagiarized code pair: test6.cpp and test3.cpp, Similarity: 0.016722209751605988\n",
            "Plagiarized code pair: test6.cpp and test1.cpp, Similarity: 0.022227376699447632\n",
            "Plagiarized code pair: test6.cpp and test2.cpp, Similarity: 0.022227376699447632\n",
            "Plagiarized code pair: test5.cpp and test3.cpp, Similarity: 0.018162373453378677\n",
            "Plagiarized code pair: test5.cpp and test1.cpp, Similarity: 0.015161887742578983\n",
            "Plagiarized code pair: test5.cpp and test2.cpp, Similarity: 0.015161887742578983\n",
            "Plagiarized code pair: test3.cpp and test1.cpp, Similarity: 0.015132594853639603\n",
            "Plagiarized code pair: test3.cpp and test2.cpp, Similarity: 0.015132594853639603\n",
            "Plagiarized code pair: test1.cpp and test2.cpp, Similarity: 0.025957347825169563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "def remove_comments_and_headers(code):\n",
        "    code = re.sub(r'//.*', '', code)\n",
        "    code = re.sub(r'/\\*[\\s\\S]*?\\*/', '', code)\n",
        "    code = re.sub(r'#include\\s*<.*>', '', code)\n",
        "    code = re.sub(r'#include\\s*\".*\"', '', code)\n",
        "    code = re.sub(r'using\\s+namespace\\s+std;', '', code)\n",
        "    return code\n",
        "\n",
        "def normalize_whitespace(code):\n",
        "    code = code.strip()\n",
        "    code = re.sub(r'\\s+', ' ', code)\n",
        "    code = re.sub(r'\\n+', '\\n', code)\n",
        "    return code\n",
        "\n",
        "def preprocess_code(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        code = file.read()\n",
        "    code = remove_comments_and_headers(code)\n",
        "    code = normalize_whitespace(code)\n",
        "    return code\n",
        "\n",
        "def preprocess_files(directory):\n",
        "    preprocessed_files = {}\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.cpp'):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            preprocessed_files[filename] = preprocess_code(file_path)\n",
        "    return preprocessed_files\n",
        "\n",
        "directory = '/content/data/tests'\n",
        "preprocessed_files = preprocess_files(directory)\n",
        "\n",
        "# Vectorize the code using TF-IDF\n",
        "def vectorize_code(preprocessed_files):\n",
        "    vectorizer = TfidfVectorizer(binary=True)\n",
        "    filenames = list(preprocessed_files.keys())\n",
        "    codes = list(preprocessed_files.values())\n",
        "    tfidf_matrix = vectorizer.fit_transform(codes)\n",
        "    return filenames, tfidf_matrix\n",
        "\n",
        "filenames, tfidf_matrix = vectorize_code(preprocessed_files)\n",
        "\n",
        "# Binarize the TF-IDF matrix\n",
        "binary_matrix = (tfidf_matrix > 0).astype(int)\n",
        "\n",
        "# Calculate Jaccard similarity between the binary vectors\n",
        "def calculate_jaccard_similarity(binary_matrix):\n",
        "    similarities = np.zeros((binary_matrix.shape[0], binary_matrix.shape[0]))\n",
        "    for i in range(binary_matrix.shape[0]):\n",
        "        for j in range(i + 1, binary_matrix.shape[0]):\n",
        "            intersection = np.sum(np.logical_and(binary_matrix[i].toarray(), binary_matrix[j].toarray()))\n",
        "            union = np.sum(np.logical_or(binary_matrix[i].toarray(), binary_matrix[j].toarray()))\n",
        "            jaccard_similarity = intersection / union if union != 0 else 0.0\n",
        "            similarities[i, j] = jaccard_similarity\n",
        "            similarities[j, i] = jaccard_similarity\n",
        "    return similarities\n",
        "\n",
        "similarity_matrix = calculate_jaccard_similarity(binary_matrix)\n",
        "\n",
        "threshold = 0.5\n",
        "def identify_plagiarized_code(filenames, similarity_matrix, threshold):\n",
        "    plagiarized_pairs = []\n",
        "    for i in range(len(filenames)):\n",
        "        for j in range(i + 1, len(filenames)):\n",
        "            if similarity_matrix[i, j] > threshold:\n",
        "                plagiarized_pairs.append((filenames[i], filenames[j], similarity_matrix[i, j]))\n",
        "    return plagiarized_pairs\n",
        "\n",
        "plagiarized_pairs = identify_plagiarized_code(filenames, similarity_matrix, threshold)\n",
        "for pair in plagiarized_pairs:\n",
        "    filename1, filename2, similarity = pair\n",
        "    print(f\"Plagiarized code pair: {filename1} and {filename2}, Similarity: {similarity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVS50VmjmkyI",
        "outputId": "dca26f63-065b-4680-a9e5-a473554440dc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plagiarized code pair: test6.cpp and test5.cpp, Similarity: 0.6285714285714286\n",
            "Plagiarized code pair: test6.cpp and test1.cpp, Similarity: 0.6944444444444444\n",
            "Plagiarized code pair: test6.cpp and test2.cpp, Similarity: 0.6944444444444444\n",
            "Plagiarized code pair: test5.cpp and test1.cpp, Similarity: 0.5263157894736842\n",
            "Plagiarized code pair: test5.cpp and test2.cpp, Similarity: 0.5263157894736842\n",
            "Plagiarized code pair: test1.cpp and test2.cpp, Similarity: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JP7GwWyin4yT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}