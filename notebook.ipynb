{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8xyGeu5cp4dg"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ZGyYsXuVq0uA"
      },
      "outputs": [],
      "source": [
        "#labels (0: not plagiarized, 1: plagiarized)\n",
        "\n",
        "file_pairs = [\n",
        "    ('/content/data/file1.cpp', '/content/data/file2.cpp', 0),\n",
        "    ('/content/data/file3.cpp', '/content/data/file4.cpp', 0),\n",
        "    ('/content/data/file5.cpp', '/content/data/file6.cpp', 1),\n",
        "    ('/content/data/file7.cpp', '/content/data/file8.cpp', 1),\n",
        "    ('/content/data/file9.cpp', '/content/data/file10.cpp', 1),\n",
        "    ('/content/data/file11.cpp', '/content/data/file12.cpp', 1),\n",
        "    ('/content/data/file13.cpp', '/content/data/file14.cpp', 0),\n",
        "    ('/content/data/file15.cpp', '/content/data/file16.cpp', 0),\n",
        "    ('/content/data/file17.cpp', '/content/data/file18.cpp', 0),\n",
        "    ('/content/data/file19.cpp', '/content/data/file20.cpp', 0),\n",
        "    ('/content/data/file21.cpp', '/content/data/file22.cpp', 0),\n",
        "    ('/content/data/file23.cpp', '/content/data/file24.cpp', 0),\n",
        "    ('/content/data/file25.cpp', '/content/data/file26.cpp', 0),\n",
        "    ('/content/data/file27.cpp', '/content/data/file28.cpp', 1),\n",
        "    ('/content/data/file29.cpp', '/content/data/file30.cpp', 1),\n",
        "    ('/content/data/file31.cpp', '/content/data/file32.cpp', 0),\n",
        "    ('/content/data/file33.cpp', '/content/data/file34.cpp', 0),\n",
        "    ('/content/data/file35.cpp', '/content/data/file36.cpp', 0),\n",
        "    ('/content/data/file37.cpp', '/content/data/file38.cpp', 1),\n",
        "    ('/content/data/file39.cpp', '/content/data/file40.cpp', 0),\n",
        "    ('/content/data/file1.cpp', '/content/data/file6.cpp', 0),\n",
        "    ('/content/data/file5.cpp', '/content/data/file8.cpp', 0),\n",
        "    ('/content/data/file9.cpp', '/content/data/file5.cpp', 0),\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "voNw_S5nr1mC"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess(file1, file2):\n",
        "    with open(file1, 'r', encoding='utf-8') as f1, open(file2, 'r', encoding='utf-8') as f2:\n",
        "        code1 = f1.read()\n",
        "        code2 = f2.read()\n",
        "    code1 = preprocess_code(code1)\n",
        "    code2 = preprocess_code(code2)\n",
        "    return code1, code2\n",
        "\n",
        "def preprocess_code(code):\n",
        "    code = re.sub(r'//.*', '', code)\n",
        "    code = re.sub(r'/\\*[\\s\\S]*?\\*/', '', code)\n",
        "    code = re.sub(r'#include\\s*<.*>', '', code)\n",
        "    code = re.sub(r'#include\\s*\".*\"', '', code)\n",
        "    code = re.sub(r'using\\s+namespace\\s+std;', '', code)\n",
        "    code = re.sub(r';', '', code)\n",
        "    code = code.strip()\n",
        "    code = re.sub(r'\\s+', ' ', code)\n",
        "    code = re.sub(r'\\n+', '\\n', code)\n",
        "    return code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cKnBhlJhr5uT"
      },
      "outputs": [],
      "source": [
        "def augment_code_sample(code_sample):\n",
        "    lines = code_sample.split(' ')\n",
        "    random.shuffle(lines)\n",
        "    return ' '.join(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rMw7tTypr8OM"
      },
      "outputs": [],
      "source": [
        "code_samples = []\n",
        "labels = []\n",
        "\n",
        "for file1, file2, label in file_pairs:\n",
        "    code1, code2 = load_and_preprocess(file1, file2)\n",
        "    code_samples.append(code1)\n",
        "    code_samples.append(code2)\n",
        "    labels.extend([label, label])\n",
        "\n",
        "    for _ in range(40):\n",
        "        augmented_code1 = augment_code_sample(code1)\n",
        "        augmented_code2 = augment_code_sample(code2)\n",
        "        code_samples.append(augmented_code1)\n",
        "        code_samples.append(augmented_code2)\n",
        "        labels.extend([label, label])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ysigvRSTr-8_"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(code_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "IhTYLU-DsBb1"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "sCQ7V4kUsFfi"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM7qpTpasIHO",
        "outputId": "240d9980-31c0-4caf-f82c-50be47cf57f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
            "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_resampled, y_resampled)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf08Yg6ysKkc",
        "outputId": "e83bac9f-1a5e-4056-deab-1cb47090a349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores: [0.85942857 0.95314286 0.67162471]\n",
            "Mean cross-validation score: 0.828065380843413\n"
          ]
        }
      ],
      "source": [
        "cv_scores = cross_val_score(grid_search.best_estimator_, X_resampled, y_resampled, cv=3)\n",
        "print(f\"Cross-validation scores: {cv_scores}\")\n",
        "print(f\"Mean cross-validation score: {cv_scores.mean()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXD4SYZUsOwi",
        "outputId": "92d10033-9aa9-4750-dc6b-a94adaab12b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.83      0.91       315\n",
            "           1       0.87      1.00      0.93       341\n",
            "\n",
            "    accuracy                           0.92       656\n",
            "   macro avg       0.93      0.92      0.92       656\n",
            "weighted avg       0.93      0.92      0.92       656\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.25, random_state=42)\n",
        "\n",
        "best_clf = grid_search.best_estimator_\n",
        "best_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = best_clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "XG_N1H25sTbO"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "InSw6zb06evh"
      },
      "outputs": [],
      "source": [
        "def predict_plagiarism(new_files_dir, model, vectorizer):\n",
        "    files = [os.path.join(new_files_dir, f) for f in os.listdir(new_files_dir) if f.endswith('.cpp')]\n",
        "    file_pairs = [(files[i], files[j]) for i in range(len(files)) for j in range(i + 1, len(files))]\n",
        "\n",
        "    predictions = []\n",
        "    plagiarism_counts = {}\n",
        "\n",
        "    for file1, file2 in file_pairs:\n",
        "        code1, code2 = load_and_preprocess(file1, file2)\n",
        "        code_combined = code1 + \" \" + code2\n",
        "        code_transformed = vectorizer.transform([code_combined])\n",
        "        prediction = model.predict(code_transformed)[0]\n",
        "        predictions.append((file1, file2, prediction))\n",
        "\n",
        "        if prediction == 1:\n",
        "            if file1 not in plagiarism_counts:\n",
        "                plagiarism_counts[file1] = 0\n",
        "            if file2 not in plagiarism_counts:\n",
        "                plagiarism_counts[file2] = 0\n",
        "            plagiarism_counts[file1] += 1\n",
        "            plagiarism_counts[file2] += 1\n",
        "\n",
        "    return predictions, plagiarism_counts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHRJBm327UjB"
      },
      "source": [
        "What the test data looks like:\n",
        "\n",
        "test1.cpp - original submission from a student\n",
        "\n",
        "test2.cpp - exact copy of test1\n",
        "\n",
        "test3.cpp - original submission from a student\n",
        "\n",
        "test4.cpp - original submission from a student\n",
        "\n",
        "test5.cpp - original submission from a student\n",
        "\n",
        "test6.cpp - changed muliple variable and function names from test1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6XyWqR66hoc",
        "outputId": "faee7758-c076-4761-86d4-e923f4b08573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plagiarized file pairs:\n",
            "Files: test6.cpp and test1.cpp -> Plagiarized: 1\n",
            "Files: test6.cpp and test2.cpp -> Plagiarized: 1\n",
            "Files: test1.cpp and test2.cpp -> Plagiarized: 1\n"
          ]
        }
      ],
      "source": [
        "new_files_dir = '/content/data/tests'\n",
        "predictions, plagiarism_counts = predict_plagiarism(new_files_dir, best_clf, vectorizer)\n",
        "\n",
        "print(\"Plagiarized file pairs:\")\n",
        "for file1, file2, pred in predictions:\n",
        "    if pred == 1:\n",
        "        print(f\"Files: {os.path.basename(file1)} and {os.path.basename(file2)} -> Plagiarized: {pred}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fN2DMMB6kuV",
        "outputId": "f9f2fb2b-ee28-4e66-a653-8bdc0987c1a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files consistently marked as plagiarized:\n"
          ]
        }
      ],
      "source": [
        "num_files = len(os.listdir(new_files_dir))\n",
        "threshold = num_files // 3\n",
        "\n",
        "plagiarized_files = [file for file, count in plagiarism_counts.items() if count > threshold]\n",
        "\n",
        "print(\"Files consistently marked as plagiarized:\")\n",
        "for file in plagiarized_files:\n",
        "    print(os.path.basename(file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF7aCFqz6r8Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
